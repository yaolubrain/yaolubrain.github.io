---
layout: post
title: 'Bidirectionally Self-Normalizing Neural Networks'
author: <strong>Yao Lu</strong>, Stephen Gould, Thalaiyasingam Ajanthan
date: 2020-07-17
details: arXiv, 2020.
comments: true
category: publication
link: https://arxiv.org/abs/2006.12169
archive: false
---

<p>
We theoretically solve the vanishing/exploding gradients problem in neural networks. Key idea: constrain signal norm in both directions via a new class of activation functions and orthogonal weight matrices.<br>
<a href="https://arxiv.org/abs/2006.12169">[paper]</a></p>
<div style="clear:both"></div>
