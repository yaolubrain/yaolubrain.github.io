<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>Yao Lu</title>

  <link rel="stylesheet" href="fonts/Sans/cmun-sans.css"></link>
  
  <meta name="author" content="Yao Lu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="./assets/stylesheet.css">
	<link rel="icon" href="./assets/brain.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yao Lu</name>
              </p>
              <p style="font-size: 15px;word-spacing:0">I am a Postdoc at Peking University.</p>
              <p style="font-size: 15px;word-spacing:0">
              I got my PhD from Australian National University and Master from University of Helsinki, both in computer science.
              </p>
              <p style="font-size: 15px;word-spacing:0">
              My research interest is neural networks, including their theory, architectures, learning algorithms and dynamics.
              </p>
              <p style="text-align:center">
                <a href="mailto:yaolubrain@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=CtDjbg4AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/yaolubrain">Twitter</a> &nbsp;/&nbsp;
                <a href="https://github.com/yaolubrain/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a><img style="width:100%;max-width:100%" alt="profile photo" src="./assets/yao.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>            
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Learning Sequence Attractors in Hopfield Networks with Hidden Neurons</papertitle>              
              <br>
              Yao Lu, Si Wu
              <br>
              <em>NeurIPS workshop on Associative Memory & Hopfield Networks</em>, 2023     
              <br>                       
              <a href="https://openreview.net/forum?id=lrfoJwxRWq">[paper]</a>       
              <a href="assets/seq_attractor_code.zip">[code]</a>       
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/hhn.png' width="200"></div>
                <div class="text">We pointed out the problem of classical Hopfield networks in generating sequences 
                                  and solved it by adding hidden neurons. A new algorithm with theoretical guarantees 
                                  is proposed to learn sequences as attractors for the networks with hidden neurons.</div>
              </div>                 
            </td>
          </tr>	

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Bidirectionally Self-Normalizing Neural Networks</papertitle>              
              <br>
              Yao Lu, Stephen Gould, Thalaiyasingam Ajanthan
              <br>
              <em>Neural Networks</em>, 2023     
              <br>                       
              <a href="https://arxiv.org/abs/2006.12169">[paper]</a>
              <a href="assets/bsnn.zip">[code]</a>
              <a href="assets/bsnn_slides.pdf">[slides]</a>
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/bsnn.png' width="200"></div>
                <div class="text">We theoretically solve the vanishing/exploding gradients problem in neural networks. Key idea: constraining signal propagation in both directions via a new class of activation functions and orthogonal weight matrices based on high-dimensional probability theory.</div>
              </div>                 
            </td>
          </tr>	
      		  
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Learning to Estimate Hidden Motions with Global Motion Aggregation</papertitle>              
              <br>
              Shihao Jiang, Dylan Campbell, Yao Lu, Hongdong Li, Richard Hartley
              <br>
              <em>IEEE International Conference on Computer Vision</em> (ICCV), 2021
              <br>
              <a href="https://arxiv.org/abs/2104.02409">[paper]</a>
              <a href="https://github.com/zacjiang/GMA">[code]</a>              
              <br>                 
              <br>                           
              <div class="container">
                <div class="image"><img src='img/gma.png' width="200"></div>
                <div class="text">We obtained the state-of-art optical flow estimation by integrating global motion features to handle occlusion.</div>
              </div>                  
            </td>
          </tr>		
          
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Learning Optical Flow from a Few Matches</papertitle>              
              <br>
              Shihao Jiang, Yao Lu, Hongdong Li, Richard Hartley
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (CVPR), 2021
              <br>
              <a href="https://arxiv.org/abs/2104.02166">[paper]</a>
              <a href="https://github.com/zacjiang/SCV">[code]</a>           
              <br>                 
              <br>
              <div class="container">
                <div class="image"><img src='img/scv.png' width="200"></div>
                <div class="text">We found high performance optical flow estimation can be achieved with a few candidate correspondences.</div>
              </div>                  
            </td>
          </tr>		

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Devon: Deformable Volume Network for Learning Optical Flow</papertitle>              
              <br>
              Yao Lu, Jack Valmadre, Heng Wang, Juho Kannala, Mehrtash Harandi, Philip Torr
              <br>
              <em>IEEE Winter Conference on Applications of Computer Vision</em> (WACV), 2020
              <br>
              <a href="https://arxiv.org/abs/1802.07351">[paper]</a>
              <a href="assets/devon.zip">[code]</a>
              <a href="assets/devon_slides.pdf">[slides]</a>    
              <br>                 
              <br>                           
              <div class="container">
                <div class="image"><img src='img/dcv.png' width="200"></div>
                <div class="text">We pointed out the problem of image warping in estimating optical flow and proposed the deformable cost volume to solve the problem.</div>
              </div>                  
            </td>
          </tr>	

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Doubly Stochastic Neighbor Embedding on Spheres</papertitle>              
              <br>
              Yao Lu, Jukka Corander, Zhirong Yang
              <br>
              <em>Pattern Recognition Letters</em>, 2019
              <br>
              <a href="https://arxiv.org/abs/1609.01977">[paper]</a>
              <a href="https://github.com/yaolubrain/DOSNES">[code]</a>
              <a href="https://yaolubrain.github.io/dosnes/">[demo]</a>
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/dosnes.png' width="200"></div>
                <div class="text">We proposed a new method for data visualization, making it on spheres!</div>
              </div>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Image Relations with Contrast Association Networks</papertitle>
              <br>
              Yao Lu, Zhirong Yang, Juho Kannala, Samuel Kaski
              <br>
              <em>International Joint Conference on Neural Networks</em> (IJCNN), 2019
              <br>
              <a href="https://arxiv.org/abs/1705.05665">[paper]</a>
              <a href="assets/can.zip">[code]</a>     
              <a href="assets/can_slides.pdf">[slides]</a>
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/cau.png' width="200"></div>
                <div class="text">We proposed a new neural network module, Contrast Association Units, to model the relations between two sets of input variables.</div>
              </div>                               
            </td>
          </tr>	

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Block Mean Approximation for Efficient Second Order Optimization</papertitle>              
              <br>
              Yao Lu, Mehrtash Harandi, Richard Hartley, Razvan Pascanu
              <br>
              <em>ICML workshop on Modern Trends in Nonconvex Optimization for Machine Learning</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1804.05484">[paper]</a>
              <a href="assets/bma_code.zip">[code]</a>
              <a href="assets/bma_slides.pdf">[slides]</a>              
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/bma.png' width="200"></div>
                <div class="text">We proposed a new matrix approximation method which allows efficient matrix inversion. We then applied the method to second order optimization algorithms for training neural networks.</div>
              </div>                    
            </td>
          </tr>	

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Oblivious Neural Network Predictions via MiniONN Transformations</papertitle>              
              <br>
              Jian Liu, Mika Juuti, Yao Lu, N. Asokan
              <br>
              <em>ACM Conference on Computer and Communications Security</em> (CCS), 2017
              <br>
              <a href="https://eprint.iacr.org/2017/452.pdf">[paper]</a>              
              <br>
              <br>          
              <div class="">              
                <div class="text">We proposed a new method for privacy-preserving predictions with trained neural networks.</div>
              </div>
            </td>
          </tr>	
				
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">             
              <papertitle>Unsupervised Learning on Neural Network Outputs: With Application in Zero-shot Learning</papertitle>
              <br>
              Yao Lu
              <br>
              <em>International Joint Conference on Artificial Intelligence</em> (IJCAI), 2016
              <br>
              <a href="https://arxiv.org/abs/1506.00990">[paper]</a>
              <a href="https://github.com/yaolubrain/ULNNO">[code]</a>              
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/zero_shot.jpg' width="200"></div>
                <div class="text">We found visual attributes of object classes can be unsuperisedly learned by applying Independent Component Analysis on the softmax outputs of a trained ConvNet. We showed such attributes can be useful for object recognition by performing zero-shot learning experiments on the ImageNet dataset of over 20,000 object classes.</div>
              </div>
            </td>
          </tr>	

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>A Fast Projected Fixed-Point Algorithm for Large Graph Matching</papertitle>              
              <br>
              Yao Lu, Kaizhu Huang, Cheng-Lin Liu
              <br>
              <em>Pattern Recognition</em>, 2016
              <br>
              <a href="https://arxiv.org/abs/1207.1114">[paper]</a>
              <a href="assets/dspfp.zip">[code]</a>     
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/graph_matching.png' width="200"></div>
                <div class="text">We designed a fast graph matching algorithm with time complexity <i>O</i>(<i>n^3</i>) per iteration, where <i>n</i> is the size of a graph. We proved its convergence rate. It takes within 10 seconds to match two graphs of 1000 nodes on a PC.</div>              
              </div>          
            </td>
          </tr>	
	
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>An Algorithm for Maximum Common Subgraph of Planar Triangulation Graphs</papertitle>              
              <br>
              Yao Lu, Horst Bunke, Cheng-Lin Liu
              <br>
              <em>Graph-Based Representations in Pattern Recognition</em> (GbR), 2013
              <br>
              <a href="assets/MCS.pdf">[paper]</a>
              <a href="assets/MCS.zip">[code]</a>              
              <br>
              <br>
              <div class="container">
                <div class="image"><img src='img/MCS.png' width="200"></div>
                <div class="text">We designed a fast Maximum Common Subgraph (MCS) algorithm for Planar Triangulation Graphs. Its time complexity is <i>O</i>(<i>mnk</i>), where <i>n</i> is the size of one graph, <i>m</i> is the size of the other graph and <i>k</i> is the size of their MCS.</div>              
              </div>
            </td>
          </tr>	

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">              
              <papertitle>Traveling Bumps and Their Collisions in a Two-Dimensional Neural Field</papertitle>              
              <br>
              Yao Lu, Yuzuru Sato, Shun-ichi Amari
              <br>
              <em>Neural Computation</em>, 2011
              <br>
              <a href="assets/traveling_bumps.pdf">[paper]</a>
              <a href="assets/traveling_bumps.zip">[code]</a>      
              <br>
              <br>                      
              <div class="container">
                <div class="image"><img src='img/traveling_bumps.png' width="200"></div>
                <div class="text">We found a unique traveling bump solution, which was unknown to exist before, in a set of two-dimensional neural network equations.</div>              
            </td>
          </tr>	

        </tbody></table>
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>            
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
           <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">             
              <papertitle>4D convolution and cost volume in CUDA</papertitle>             
              <br>
              Yao Lu
              <br>
              <a href="https://github.com/yaolubrain/Conv4D">[code]</a>             
            </td>
          </tr>		
     		  
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">             
              <papertitle>A Simple ConvNet in 200 MATLAB lines</papertitle>             
              <br>
              Yao Lu
              <br>
              <a href="https://github.com/yaolubrain/cnn_linear_max">[code]</a>             
            </td>
          </tr>		
		
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">            
              <papertitle>Twitter Sentiment Analysis using ConvNet</papertitle>              
              <br>
              Han Xiao, Yao Lu
              <br><a href="https://github.com/xiaohan2012/twitter-sent-dnn">[code]</a>              
            </td>
          </tr>	
        
        </tbody></table>
	      
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Site template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </tbody></table>

</body></html>
